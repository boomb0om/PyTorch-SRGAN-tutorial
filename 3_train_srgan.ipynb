{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.cuda.amp as amp\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import SRDataset\n",
    "from loss import PerceptionLoss\n",
    "from models import Generator, Discriminator\n",
    "from utils import init_torch_seeds, convert_image\n",
    "\n",
    "from PIL import PngImagePlugin\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = 100 * (1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-secondary",
   "metadata": {},
   "source": [
    "Почти все параметры обучения идентичны тем, которые были использованы при обучении SRResNet на прошлом шаге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры датасета\n",
    "augments = {\n",
    "    'rotation': False,\n",
    "    'hflip' : True\n",
    "}\n",
    "crop_size = 256\n",
    "lr_img_type = 'imagenet-norm'\n",
    "hr_img_type = '[-1, 1]'\n",
    "train_data_name = './jsons/train_images.json'\n",
    "\n",
    "# параметры обучения модели\n",
    "save_every = 30\n",
    "print_every = 143\n",
    "start_epoch = 0\n",
    "iters = 1e5\n",
    "batch_size = 24\n",
    "lr = 1e-4\n",
    "perception_loss_modifier = 0.06\n",
    "beta = 1e-3 # модификатор adversarial ошибки\n",
    "manualSeed = None\n",
    "workers = 12\n",
    "\n",
    "# параметры структуры модели\n",
    "srresnet_checkpoint = './weights/SRResNet_16blocks_4x.pth' # путь к весам SRResNet, обученной на предыдущем этапе\n",
    "upscale_factor = 4\n",
    "n_blocks = 16\n",
    "\n",
    "# Зададим рандомный seed, чтобы была возможность воспроизвести результат\n",
    "if manualSeed is None:\n",
    "    manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "init_torch_seeds(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-friend",
   "metadata": {},
   "source": [
    "Создаем SRDataset и dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SRDataset(crop_size=crop_size, scaling_factor=upscale_factor,\n",
    "                    lr_img_type=lr_img_type, hr_img_type=hr_img_type,\n",
    "                    train_data_name=train_data_name, augments=augments)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         pin_memory=True,\n",
    "                                         num_workers=int(workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-relaxation",
   "metadata": {},
   "source": [
    "Создадим генератор и дискриминатор, функции ошибки, оптимизаторы для генератора и дискриминатора (будем использовать Adam).<br>\n",
    "В качестве функции ошибки мы используем взвешенную сумму **PerceptionLoss** и **BCEWithLogitsLoss**. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# создаем генератор и дискриминатор\n",
    "generator = Generator(n_blocks=n_blocks, scaling_factor=upscale_factor).to(device)\n",
    "generator.load_state_dict(torch.load(srresnet_checkpoint)) # инициализируем модель весами srresnet\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# инициализируем loss-ы\n",
    "perception_criterion = PerceptionLoss().to(device) # MSE в пространстве фичей vgg19\n",
    "adversarial_criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# переводим в режим обучения\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "\n",
    "epochs = int(iters // len(dataloader))\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "optimizer_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "\n",
    "scaler_g = amp.GradScaler()\n",
    "scaler_d = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-individual",
   "metadata": {},
   "source": [
    "Запускаем обучение!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-adult",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    g_avg_loss = 0.0\n",
    "    d_avg_loss = 0.0\n",
    "    for i, (lr_imgs, hr_imgs) in progress_bar:\n",
    "        lr_imgs = lr_imgs.to(device)\n",
    "        hr_imgs = hr_imgs.to(device)\n",
    "        \n",
    "        ### сначала обновляем дискриминатор\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        with amp.autocast():\n",
    "            sr_imgs = generator(lr_imgs)\n",
    "            \n",
    "            hr_labels = discriminator(hr_imgs)\n",
    "            fake_labels = discriminator(sr_imgs.detach())\n",
    "            \n",
    "            # Binary Cross-Entropy loss\n",
    "            d_loss = adversarial_criterion(fake_labels, torch.zeros_like(fake_labels)) + \\\n",
    "                               adversarial_criterion(hr_labels, torch.ones_like(hr_labels))\n",
    "        \n",
    "        # back propagation\n",
    "        scaler_d.scale(d_loss).backward()\n",
    "        scaler_d.step(optimizer_d)\n",
    "        scaler_d.update()\n",
    "        \n",
    "        ### обновляем генератор\n",
    "        optimizer_g.zero_grad()\n",
    "        \n",
    "        with amp.autocast():\n",
    "            # получаем fake high res изображения\n",
    "            sr_imgs = generator(lr_imgs)\n",
    "            \n",
    "            # предсказания дискриминатора на фейковых изображениях\n",
    "            fake_labels = discriminator(sr_imgs)\n",
    "\n",
    "            # считаем loss-ы\n",
    "            perception_loss = perception_loss_modifier * perception_criterion(sr_imgs, hr_imgs.detach())\n",
    "            adversarial_loss = beta * adversarial_criterion(fake_labels, torch.ones_like(fake_labels))\n",
    "            g_loss = perception_loss + adversarial_loss\n",
    "\n",
    "        # back propagation\n",
    "        scaler_g.scale(g_loss).backward()\n",
    "        scaler_g.step(optimizer_g)\n",
    "        scaler_g.update()\n",
    "\n",
    "        d_avg_loss += d_loss.item()\n",
    "        g_avg_loss += g_loss.item()\n",
    "\n",
    "        progress_bar.set_description(f\"[{epoch + 1}/{epochs}][{i + 1}/{len(dataloader)}] \"\n",
    "                                     f\"Loss_D: {d_loss.item():.4f} Loss_G: {g_loss.item():.4f} \")\n",
    "\n",
    "        total_iter = len(dataloader) * epoch + i\n",
    "        \n",
    "        if i % print_every == 0 and i != 0:\n",
    "            print(f\"Avg Loss_G: {(g_avg_loss/(i+1)):.4f} Avg Loss_D: {(d_avg_loss/(i+1)):.4f}\")\n",
    "\n",
    "            \n",
    "    # сохраняем модели\n",
    "    if (epoch+1)%save_every == 0:\n",
    "        torch.save(generator.state_dict(), \n",
    "                   f\"./weights/SRGAN_{n_blocks}blocks_{upscale_factor}x_epoch{(epoch+1)}.pth\")\n",
    "    else:\n",
    "        torch.save(generator.state_dict(), f\"./weights/SRGAN_{n_blocks}blocks_{upscale_factor}x.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-hygiene",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
