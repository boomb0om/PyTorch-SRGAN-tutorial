{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "organized-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.cuda.amp as amp\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import SRDataset\n",
    "from loss import PerceptionLoss\n",
    "from models import Generator, Discriminator\n",
    "from utils import init_torch_seeds, convert_image\n",
    "\n",
    "from PIL import PngImagePlugin\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = 100 * (1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-spice",
   "metadata": {},
   "source": [
    "Почти все параметры обучения идентичны тем, которые были использованы при обучении SRResNet на прошлом шаге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "directed-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  7283\n"
     ]
    }
   ],
   "source": [
    "# параметры датасета\n",
    "augments = {\n",
    "    'rotation': False,\n",
    "    'hflip' : True\n",
    "}\n",
    "crop_size = 256\n",
    "lr_img_type = 'imagenet-norm'\n",
    "# так как мы оптимизируем не попиксельную MSE, а MSE в пространстве фичей сетки vgg19, которая на вход\n",
    "# принимает нормированные изображения, то тип hr изображений будет imagenet-normed\n",
    "hr_img_type = 'imagenet-norm'\n",
    "train_data_name = './jsons/train_images.json'\n",
    "\n",
    "# параметры обучения модели\n",
    "save_every = 2\n",
    "print_every = 2000\n",
    "start_epoch = 0\n",
    "iters = 1e5\n",
    "batch_size = 16\n",
    "lr = 2e-4\n",
    "beta = 1e-3 # модификатор adversarial ошибки (см. ориг. статью https://arxiv.org/pdf/1609.04802.pdf)\n",
    "manualSeed = None\n",
    "workers = 4\n",
    "\n",
    "# параметры структуры модели\n",
    "srresnet_checkpoint = './weights/SRResNet_16blocks_4x.pth' # путь к весам SRResNet, обученной на предыдущем этапе\n",
    "upscale_factor = 4\n",
    "n_blocks = 16\n",
    "\n",
    "# Зададим рандомный seed, чтобы была возможность воспроизвести результат\n",
    "if manualSeed is None:\n",
    "    manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "init_torch_seeds(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-mercury",
   "metadata": {},
   "source": [
    "Создаем SRDataset и dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tropical-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SRDataset(crop_size=crop_size, scaling_factor=upscale_factor,\n",
    "                    lr_img_type=lr_img_type, hr_img_type=hr_img_type,\n",
    "                    train_data_name=train_data_name, augments=augments)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         pin_memory=True,\n",
    "                                         num_workers=int(workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-pavilion",
   "metadata": {},
   "source": [
    "Создадим генератор и дискриминатор, функции ошибки, оптимизаторы для генератора и дискриминатора (будем использовать Adam).<br>\n",
    "В качестве функции ошибки мы используем **PerceptionLoss** и **BCEWithLogitsLoss**. <br>\n",
    "**BCEWithLogitsLoss** - состязательная ошибка (**adversarial loss**), которая используется при обучении GAN-ов.<br> \n",
    "**PerceptionLoss** - MSE в пространстве фичей vgg19. <br>\n",
    "Финальный loss: loss = **PerceptionLoss** + beta * **BCEWithLogitsLoss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "loaded-press",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# создаем генератор и дискриминатор\n",
    "generator = Generator(n_blocks=n_blocks, scaling_factor=upscale_factor).to(device)\n",
    "generator.load_state_dict(torch.load(srresnet_checkpoint)) # инициализируем модель весами srresnet\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# инициализируем loss-ы\n",
    "perception_criterion = PerceptionLoss().to(device) # MSE в пространстве фичей vgg19\n",
    "adversarial_criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# переводим в режим обучения\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "\n",
    "epochs = int(iters // len(dataloader))\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "optimizer_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "\n",
    "scaler_g = amp.GradScaler()\n",
    "scaler_d = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-script",
   "metadata": {},
   "source": [
    "Запускаем обучение!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "revised-exhaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/19][2001/5136] Loss_D: 0.0000 Loss_G: 4.9509 :  39%|███▉      | 2001/5136 [07:45<12:01,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 4.4721 Avg Loss_D: 0.2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/19][4001/5136] Loss_D: 0.0001 Loss_G: 4.1077 :  78%|███████▊  | 4001/5136 [15:25<04:20,  4.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 4.3553 Avg Loss_D: 0.1475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/19][5136/5136] Loss_D: 0.0052 Loss_G: 3.6789 : 100%|██████████| 5136/5136 [19:53<00:00,  4.30it/s] \n",
      "[2/19][2001/5136] Loss_D: 0.0000 Loss_G: 4.1856 :  39%|███▉      | 2001/5136 [07:41<12:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 4.1216 Avg Loss_D: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2/19][4001/5136] Loss_D: 0.0001 Loss_G: 3.1869 :  78%|███████▊  | 4001/5136 [15:21<04:21,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 4.1099 Avg Loss_D: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2/19][5136/5136] Loss_D: 0.0000 Loss_G: 3.3755 : 100%|██████████| 5136/5136 [19:45<00:00,  4.33it/s]\n",
      "[3/19][2001/5136] Loss_D: 0.0000 Loss_G: 4.0556 :  39%|███▉      | 2001/5136 [07:43<12:20,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 4.0261 Avg Loss_D: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3/19][4001/5136] Loss_D: 0.0000 Loss_G: 4.3282 :  78%|███████▊  | 4001/5136 [15:23<04:24,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 4.0152 Avg Loss_D: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3/19][5136/5136] Loss_D: 0.0000 Loss_G: 4.3984 : 100%|██████████| 5136/5136 [19:43<00:00,  4.34it/s]\n",
      "[4/19][2001/5136] Loss_D: 0.0000 Loss_G: 3.5953 :  39%|███▉      | 2001/5136 [07:39<11:59,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 3.9688 Avg Loss_D: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4/19][4001/5136] Loss_D: 0.0000 Loss_G: 4.7709 :  78%|███████▊  | 4001/5136 [15:19<04:20,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 3.9620 Avg Loss_D: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4/19][5136/5136] Loss_D: 0.0000 Loss_G: 4.3521 : 100%|██████████| 5136/5136 [19:40<00:00,  4.35it/s]\n",
      "[5/19][2001/5136] Loss_D: 0.0000 Loss_G: 3.6637 :  39%|███▉      | 2001/5136 [07:40<12:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 3.9392 Avg Loss_D: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[5/19][4001/5136] Loss_D: 0.0000 Loss_G: 4.0640 :  78%|███████▊  | 4001/5136 [15:20<04:22,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 3.9279 Avg Loss_D: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[5/19][5136/5136] Loss_D: 0.0000 Loss_G: 4.8965 : 100%|██████████| 5136/5136 [19:42<00:00,  4.34it/s]\n",
      "[6/19][2001/5136] Loss_D: 0.0000 Loss_G: 4.2990 :  39%|███▉      | 2001/5136 [07:41<12:05,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 3.8976 Avg Loss_D: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[6/19][4001/5136] Loss_D: 0.0000 Loss_G: 3.4976 :  78%|███████▊  | 4001/5136 [15:21<04:20,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 3.8854 Avg Loss_D: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[6/19][5136/5136] Loss_D: 0.0000 Loss_G: 2.7696 : 100%|██████████| 5136/5136 [19:41<00:00,  4.35it/s]\n",
      "[7/19][2001/5136] Loss_D: 0.0000 Loss_G: 3.7446 :  39%|███▉      | 2001/5136 [07:40<11:57,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 3.8623 Avg Loss_D: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[7/19][4001/5136] Loss_D: 0.0000 Loss_G: 3.7017 :  78%|███████▊  | 4001/5136 [15:20<04:38,  4.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss_G: 3.8494 Avg Loss_D: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[7/19][5136/5136] Loss_D: 0.0000 Loss_G: 3.6677 : 100%|██████████| 5136/5136 [19:42<00:00,  4.34it/s]\n",
      "[8/19][251/5136] Loss_D: 0.0000 Loss_G: 3.6674 :   5%|▍         | 251/5136 [00:58<19:02,  4.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-422f4e1b3737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# back propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mscaler_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperceptual_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mscaler_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mscaler_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    g_avg_loss = 0.0\n",
    "    d_avg_loss = 0.0\n",
    "    for i, (lr_imgs, hr_imgs) in progress_bar:\n",
    "        lr_imgs = lr_imgs.to(device, non_blocking=True)\n",
    "        hr_imgs = hr_imgs.to(device, non_blocking=True)\n",
    "        \n",
    "        ### сначала обновляем генератор\n",
    "        optimizer_g.zero_grad()\n",
    "        \n",
    "        with amp.autocast():\n",
    "            # получаем fake high res изображения\n",
    "            sr_imgs = generator(lr_imgs)\n",
    "            # в vgg19 на вход нужно подавать отнормированные изображения\n",
    "            sr_imgs = convert_image(sr_imgs, source='[-1, 1]', target='imagenet-norm')\n",
    "            \n",
    "            fake_labels = discriminator(sr_imgs)\n",
    "\n",
    "            # считаем loss-ы\n",
    "            perception_loss = perception_criterion(sr_imgs, hr_imgs)\n",
    "            adversarial_loss = adversarial_criterion(fake_labels, torch.ones_like(fake_labels))\n",
    "            perceptual_loss = perception_loss + beta * adversarial_loss\n",
    "\n",
    "        # back propagation\n",
    "        scaler_g.scale(perceptual_loss).backward()\n",
    "        scaler_g.step(optimizer_g)\n",
    "        scaler_g.update()\n",
    "        \n",
    "        ### обновляем дискриминатор\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        with amp.autocast():\n",
    "            hr_labels = discriminator(hr_imgs)\n",
    "            fake_labels = discriminator(sr_imgs.detach())\n",
    "            \n",
    "            # Binary Cross-Entropy loss\n",
    "            adversarial_loss = adversarial_criterion(fake_labels, torch.zeros_like(fake_labels)) + \\\n",
    "                               adversarial_criterion(hr_labels, torch.ones_like(hr_labels))\n",
    "        \n",
    "        scaler_d.scale(adversarial_loss).backward()\n",
    "        scaler_d.step(optimizer_d)\n",
    "        scaler_d.update()\n",
    "\n",
    "        d_avg_loss += adversarial_loss.item()\n",
    "        g_avg_loss += perceptual_loss.item()\n",
    "\n",
    "        progress_bar.set_description(f\"[{epoch + 1}/{epochs}][{i + 1}/{len(dataloader)}] \"\n",
    "                                     f\"Loss_D: {adversarial_loss.item():.4f} Loss_G: {perceptual_loss.item():.4f} \")\n",
    "\n",
    "        total_iter = len(dataloader) * epoch + i\n",
    "        \n",
    "        if i % print_every == 0 and i != 0:\n",
    "            print(f\"Avg Loss_G: {(g_avg_loss/(i+1)):.4f} Avg Loss_D: {(d_avg_loss/(i+1)):.4f}\")\n",
    "\n",
    "            \n",
    "    # сохраняем модели\n",
    "    if (epoch+1)%save_every == 0:\n",
    "        torch.save(generator.state_dict(), \n",
    "                   f\"./weights/SRGAN_{n_blocks}blocks_{upscale_factor}x_epoch{(epoch+1)}.pth\")\n",
    "    else:\n",
    "        torch.save(generator.state_dict(), f\"./weights/SRGAN_{n_blocks}blocks_{upscale_factor}x.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-nicholas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
