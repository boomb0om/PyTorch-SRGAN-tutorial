{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hungarian-pound",
   "metadata": {},
   "source": [
    "<b>Перед запуском ячеек убедитесь, что все необходимые зависимости установлены!<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.cuda.amp as amp\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import SRDataset\n",
    "from models import Generator\n",
    "from utils import init_torch_seeds\n",
    "\n",
    "from PIL import PngImagePlugin\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = 100 * (1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-quantity",
   "metadata": {},
   "source": [
    "Теперь установим все параметры для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры датасета\n",
    "# аугментация изображений (повороты и отражение по горизонтали): позволяет разнообразить изображения в датасете\n",
    "augments = {\n",
    "    'rotation': False,  # поворот на 90, 180 или 270 градусов\n",
    "    'hflip' : True      # отражение по горизонтали\n",
    "}\n",
    "crop_size = 256 # размер обрезки целевого hr изображения\n",
    "lr_img_type = 'imagenet-norm' # тип, к которому приводим lr изображение\n",
    "hr_img_type = '[-1, 1]' # тип, к которому приводим hr изображение\n",
    "train_data_name = './jsons/train_images.json' # путь к json, полученному на стадии подготовки датасета\n",
    "\n",
    "# параметры обучения модели\n",
    "save_every = 20 # сохранять модель каждые save_every эпох\n",
    "print_every = 140 # количество итераций для вывода статистики\n",
    "start_epoch = 0 # начальная эпоха\n",
    "iters = 2e5 # общее количество итераций\n",
    "batch_size = 24 # размер батча\n",
    "lr = 2e-4 # скорость обучения\n",
    "manualSeed = None # позволяет воспроизвести результат с определеным seed-ом\n",
    "workers = 8\n",
    "\n",
    "# параметры структуры модели\n",
    "upscale_factor = 4 # во сколько раз увеличиваем размер изображения\n",
    "n_blocks = 16 # кол-во residual блоков в моделе\n",
    "\n",
    "# Зададим рандомный seed, чтобы была возможность воспроизвести результат\n",
    "if manualSeed is None:\n",
    "    manualSeed = random.randint(1, 10000)\n",
    "random.seed(manualSeed)\n",
    "init_torch_seeds(manualSeed)\n",
    "print(\"Random Seed: \", manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-plenty",
   "metadata": {},
   "source": [
    "Теперь создадим кастомный датасет `SRDataset` и dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SRDataset(crop_size=crop_size, scaling_factor=upscale_factor,\n",
    "                    lr_img_type=lr_img_type, hr_img_type=hr_img_type,\n",
    "                    train_data_name=train_data_name, augments=augments)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         pin_memory=True,\n",
    "                                         num_workers=int(workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-causing",
   "metadata": {},
   "source": [
    "Создадим генератор, loss, оптимизатор (будем использовать Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Если на устройстве установлена cuda, то pytorch выберет видеокарту в качестве вычислительного устройства, \n",
    "#иначе все вычисления будут производиться на процессоре\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем объект нашей нейросети\n",
    "generator = Generator(n_blocks=n_blocks, scaling_factor=upscale_factor).to(device)\n",
    "generator.train() # переводим в режим обучения\n",
    "\n",
    "# создаем loss, оптимизатор и scaler\n",
    "content_criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "scaler = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-paris",
   "metadata": {},
   "source": [
    "Запускаем обучение SRResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-singer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "psnr_epochs = int(iters // len(dataloader))\n",
    "\n",
    "for epoch in range(start_epoch, psnr_epochs):\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    avg_loss = 0.0\n",
    "    for i, (lr_imgs, hr_imgs) in progress_bar:\n",
    "        # получаем lowres(input) и highres(target) изображения\n",
    "        lr = lr_imgs.to(device, non_blocking=True)\n",
    "        hr = hr_imgs.to(device, non_blocking=True)\n",
    "    \n",
    "        optimizer.zero_grad() # зануляем градиенты\n",
    "        with amp.autocast():  # amp.autocast() немного ускоряет вычисления в forward pass-е\n",
    "            # генерируем \"фейковые\" изображения высокого разрешения из входного изображения низкого разрешения\n",
    "            sr = generator(lr)\n",
    "            # считаем попиксельную MSE у фейкового и настоящего изображений\n",
    "            mse_loss = content_criterion(sr, hr)\n",
    "            \n",
    "        # backpropagation\n",
    "        scaler.scale(mse_loss).backward()\n",
    "        # обновляем веса модели\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    \n",
    "        #обновляем статистику и progress bar\n",
    "        avg_loss += mse_loss.item()\n",
    "        progress_bar.set_description(f\"[{epoch + 1}/{psnr_epochs}][{i + 1}/{len(dataloader)}] \"\n",
    "                                     f\"MSE loss: {mse_loss.item():.4f}\")\n",
    "        total_iter = len(dataloader) * epoch + i\n",
    "        \n",
    "        if i % print_every == 0 and i!=0:\n",
    "            print(f\"MSE loss: {(avg_loss/(i+1)):.4f}\")\n",
    "    \n",
    "    # сохраняем модели\n",
    "    if (epoch+1)%save_every == 0:\n",
    "        torch.save(generator.state_dict(),\n",
    "                   f\"./weights/SRResNet_{n_blocks}blocks_{upscale_factor}x_epoch{(epoch+1)}.pth\")\n",
    "    else:\n",
    "        torch.save(generator.state_dict(), f\"./weights/SRResNet_{n_blocks}blocks_{upscale_factor}x.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-pound",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
