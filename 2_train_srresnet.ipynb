{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "applicable-luxury",
   "metadata": {},
   "source": [
    "<b>Перед запуском ячеек убедитесь, что все необходимые зависимости установлены!<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "similar-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.cuda.amp as amp\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import SRDataset\n",
    "from models import Generator\n",
    "from utils import init_torch_seeds\n",
    "\n",
    "from PIL import PngImagePlugin\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = 100 * (1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-graduation",
   "metadata": {},
   "source": [
    "Теперь установим все параметры для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "disciplinary-asset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  8548\n"
     ]
    }
   ],
   "source": [
    "# параметры датасета\n",
    "# аугментация изображений (повороты и горизонтальное отражение): позволяет увеличить кол-во изображений в датасете\n",
    "augments = {\n",
    "    'rotation': False,  #поворот на 90, 180 или 270 градусов\n",
    "    'hflip' : True      #горизонтальное отражение изображения\n",
    "}\n",
    "crop_size = 256 # размер обрезки целевого hr изображения\n",
    "lr_img_type = 'imagenet-norm' # тип, к которому приводим lr изображение\n",
    "hr_img_type = '[-1, 1]' # тип, к которому приводим hr изображение\n",
    "train_data_name = './jsons/train_images.json' # путь к json, полученному на стадии подготовки датасета\n",
    "\n",
    "# параметры обучения модели\n",
    "save_every = 2 # сохранять модель каждые save_every эпох\n",
    "print_every = 2000 # количество итераций для вывода статистики\n",
    "start_epoch = 0 # начальная эпоха\n",
    "iters = 2e5 # общее количество итераций\n",
    "batch_size = 16 # размер батча\n",
    "lr = 2e-4 # скорость обучения\n",
    "manualSeed = None # позволяет воспроизвести результат с определеным seed-ом\n",
    "workers = 4 \n",
    "\n",
    "# параметры структуры модели\n",
    "upscale_factor = 4 # во сколько раз увеличиваем размер изображения\n",
    "n_blocks = 16 # кол-во residual блоков в моделе\n",
    "\n",
    "# Зададим рандомный seed, чтобы была возможность воспроизвести результат\n",
    "if manualSeed is None:\n",
    "    manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "init_torch_seeds(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-course",
   "metadata": {},
   "source": [
    "Теперь создадим кастомный датасет `SRDataset` и dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "floral-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SRDataset(crop_size=crop_size, scaling_factor=upscale_factor,\n",
    "                    lr_img_type=lr_img_type, hr_img_type=hr_img_type,\n",
    "                    train_data_name=train_data_name, augments=augments)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         pin_memory=True,\n",
    "                                         num_workers=int(workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-criterion",
   "metadata": {},
   "source": [
    "Создадим генератор, loss, оптимизатор (будем использовать Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generic-dance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Если на устройстве установлена cuda, то pytorch выберет видеокарту в качестве вычислительного устройства, \n",
    "#иначе все вычисления будут производиться на процессоре (не советую обучать на CPU, т.к. это будет\n",
    "#в ~40 раз дольше, чем на GPU).\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)\n",
    "\n",
    "# создаем объект нашей нейросети\n",
    "generator = Generator(n_blocks=n_blocks, scaling_factor=upscale_factor).to(device)\n",
    "generator.train() # переводим в режим обучения\n",
    "\n",
    "# создаем loss, оптимизатор и scaler\n",
    "content_criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "scaler = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-novel",
   "metadata": {},
   "source": [
    "Запускаем обучение SRResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-terror",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/38][1834/5186] MSE loss: 0.0117:  35%|███▌      | 1834/5186 [03:31<06:16,  8.89it/s]"
     ]
    }
   ],
   "source": [
    "psnr_epochs = int(iters // len(dataloader))\n",
    "\n",
    "for epoch in range(start_epoch, psnr_epochs):\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    avg_loss = 0.0\n",
    "    for i, (lr_imgs, hr_imgs) in progress_bar:\n",
    "        # получаем lowres(input) и highres(target) изображения\n",
    "        lr = lr_imgs.to(device, non_blocking=True)\n",
    "        hr = hr_imgs.to(device, non_blocking=True)\n",
    "    \n",
    "        optimizer.zero_grad() # зануляем градиенты\n",
    "        with amp.autocast():  # amp.autocast() немного ускоряет вычисления в forward pass-е\n",
    "            # генерируем \"фейковые\" изображения высокого разрешения из входного изображения низкого разрешения\n",
    "            sr = generator(lr)\n",
    "            # считаем попиксельную MSE у фейкового и настоящего изображений\n",
    "            mse_loss = content_criterion(sr, hr)\n",
    "            \n",
    "        # backpropagation\n",
    "        scaler.scale(mse_loss).backward()\n",
    "        # обновляем веса модели\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    \n",
    "        #обновляем статистику и progress bar\n",
    "        avg_loss += mse_loss.item()\n",
    "        progress_bar.set_description(f\"[{epoch + 1}/{psnr_epochs}][{i + 1}/{len(dataloader)}] \"\n",
    "                                     f\"MSE loss: {mse_loss.item():.4f}\")\n",
    "        total_iter = len(dataloader) * epoch + i\n",
    "        \n",
    "        if i % print_every == 0 and i!=0:\n",
    "            print(f\"MSE loss: {(avg_loss/(i+1)):.4f}\")\n",
    "    \n",
    "    # сохраняем модели\n",
    "    if (epoch+1)%save_every == 0:\n",
    "        torch.save(generator.state_dict(),\n",
    "                   f\"./weights/SRResNet_{n_blocks}blocks_{upscale_factor}x_epoch{(epoch+1)}.pth\")\n",
    "    else:\n",
    "        torch.save(generator.state_dict(), f\"./weights/SRResNet_{n_blocks}blocks_{upscale_factor}x.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-roberts",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
